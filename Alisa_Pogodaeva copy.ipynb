{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import threading \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import snakes.plugins\n",
    "snakes.plugins.load(\"gv\", \"snakes.nets\", \"nets\")\n",
    "from nets import *\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import spacy.displacy as displacy\n",
    "#import coreferee\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp.add_pipe(\"coreferee\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_words = {\"and\", \"both\", \"along with\", \"as well as\", \"in conjunction with\", \"together with\"}\n",
    "individual_words = {\"or\", \"either\", \"one of\", \"neither\", \"nor\", \"any of\", \"each of\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [places, moves], Nouns: [table, (on), chair, None])\n"
     ]
    }
   ],
   "source": [
    "#Entities\n",
    "\n",
    "class Preposition:\n",
    "    def __init__(self, name, tag=None):\n",
    "        self.name = name\n",
    "        self.tag = tag  # Stores the syntactic role (e.g., \"prep\", \"mark\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.name}, TAG: {self.tag})\" if self.tag else f\"({self.name})\"\n",
    "\n",
    "    \n",
    "class Verb:\n",
    "    def __init__(self, name, preposition=None, tag=None):\n",
    "        self.name = name\n",
    "        self.preposition = [preposition] if preposition and not isinstance(preposition, list) else (preposition or [])\n",
    "        self.tag = tag  # Stores the syntactic role of the verb (e.g., \"advcl\", \"root\")\n",
    "\n",
    "    def __str__(self):\n",
    "        prepositions = ', '.join(str(p) for p in self.preposition) if self.preposition else ''\n",
    "        tag_str = f\"TAG: {self.tag}\" if self.tag else ''\n",
    "        \n",
    "        components = [self.name]\n",
    "        if prepositions:\n",
    "            components.append(f\"Prepositions: {prepositions}\")\n",
    "        if tag_str:\n",
    "            components.append(tag_str)\n",
    "        \n",
    "        return ', '.join(components)\n",
    "\n",
    "\n",
    "class Noun:\n",
    "    def __init__(self, name, preposition=None):\n",
    "        self.name = name\n",
    "        self.preposition = preposition if isinstance(preposition, list) else [preposition]\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.preposition:\n",
    "            p = ', '.join(str(p) for p in self.preposition)\n",
    "            return f\"{self.name}, {p}\"\n",
    "        else:\n",
    "            return f\"{self.name}\"\n",
    "\n",
    "    \n",
    "class Task:\n",
    "    def __init__(self, verbs, nouns, subtask=None):\n",
    "        self.verbs = verbs if isinstance(verbs, list) else [verbs] \n",
    "        self.nouns = nouns if isinstance(nouns, list) else [nouns]\n",
    "        self.subtask = subtask if isinstance(subtask, Task) else None  # Optional subtask\n",
    "\n",
    "    def __str__(self):\n",
    "        verb_str = ', '.join(str(verb) for verb in self.verbs)\n",
    "        nouns_str = ', '.join(str(noun) for noun in self.nouns)\n",
    "        subtask_str = f\", Subtask: ({self.subtask})\" if self.subtask else \"\"\n",
    "\n",
    "        return f\"Task(Verbs: [{verb_str}], Nouns: [{nouns_str}]{subtask_str})\"\n",
    "\n",
    "    def get_all_actors(self):\n",
    "        actors = [noun.name for noun in self.nouns]\n",
    "        if self.subtask:\n",
    "            actors.extend(self.subtask.get_all_actors())  # Include subtask actors\n",
    "        return actors\n",
    "\n",
    "\n",
    "\n",
    "preposition1 = Preposition(\"on\")\n",
    "noun1 = Noun(\"table\", preposition1)\n",
    "noun2 = Noun(\"chair\")\n",
    "\n",
    "# Create a list of verbs\n",
    "verbs = Task([\"places\", \"moves\"], [noun1, noun2])\n",
    "\n",
    "# Print out the verb and its related nouns and prepositions\n",
    "print(verbs)  # Output: Verb(places, moves, Noun(table, floor, Preposition(on)), Noun(chair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_tree(doc):\n",
    "\n",
    "    all_tasks = []\n",
    "\n",
    "    def add_actors(subj):\n",
    "        prepositions = []\n",
    "        collect_prepositions(subj, prepositions)\n",
    "        actor = Noun(subj.text, prepositions)\n",
    "        return actor\n",
    "    \n",
    "    def add_task(verbs, actors):\n",
    "        if len(actors) == 0:\n",
    "            actors.append(Noun(\"Some_Actor\"))\n",
    "        task = Task(verbs, actors)\n",
    "        return task\n",
    "    \n",
    "    def add_verb(verb, tag):\n",
    "        prepositions = []\n",
    "        collect_prepositions(verb, prepositions)  \n",
    "        verb1 = Verb(verb.text, preposition=prepositions, tag=tag)\n",
    "        return verb1\n",
    "\n",
    "    def collect_subj_conjuncts(subj, actors):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"conj\":\n",
    "                actor = add_actors(child)\n",
    "                actors.append(actor)\n",
    "                collect_subj_conjuncts(child, actors)\n",
    "    \n",
    "    def collect_prepositions(subj, prepositions):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"cc\":\n",
    "                preposition = Preposition(child.text, tag=\"cc\")\n",
    "                prepositions.append(preposition)\n",
    "\n",
    "            if child.dep_ == \"mark\":\n",
    "                preposition = Preposition(child.text, tag=\"mark\")\n",
    "                prepositions.append(preposition)\n",
    "            \n",
    "            if child.dep_ == \"advmod\":\n",
    "                preposition = Preposition(child.text, tag=\"advmod\")\n",
    "                prepositions.append(preposition)\n",
    "            \n",
    "            if child.dep_ == \"prep\":\n",
    "                preposition = Preposition(child.text, tag=\"prep\")\n",
    "                prepositions.append(preposition)\n",
    "            \n",
    "\n",
    "    def collect_conjuncts(verb, task):\n",
    "        for child in verb.children:\n",
    "            if child.dep_ == \"conj\" and child.pos_ == \"VERB\":\n",
    "                conj_nsubj = []\n",
    "\n",
    "                # Check if the conjunct verb has its own subject\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ == \"nsubj\":\n",
    "                        actor = add_actors(grandchild)\n",
    "                        conj_nsubj.append(actor)\n",
    "                        collect_subj_conjuncts(grandchild, conj_nsubj)\n",
    "\n",
    "                 # Add a tag \n",
    "                verb = add_verb(child, tag=\"conj\")\n",
    "\n",
    "                # If no subject for the conjunct verb, add it to the root's verbs\n",
    "                if not conj_nsubj:\n",
    "                    task.verbs.append(verb) \n",
    "                else:\n",
    "                    task = add_task(verb, conj_nsubj)\n",
    "                    all_tasks.append(task)\n",
    "\n",
    "                collect_conjuncts(child, task)\n",
    "\n",
    "            if child.dep_ == \"advcl\" and child.pos_ == \"VERB\":\n",
    "                conj_nsubj = []\n",
    "                # Check if the sub verb has its own subject\n",
    "                for grandchild in child.children:                   \n",
    "                    if grandchild.dep_ == \"nsubj\":\n",
    "                        actor = add_actors(grandchild)\n",
    "                        conj_nsubj.append(actor)\n",
    "                        collect_subj_conjuncts(grandchild, conj_nsubj)\n",
    "                # Add a tag \n",
    "                verb = add_verb(child, tag=\"advcl\")\n",
    "\n",
    "                # Add a new subtask\n",
    "                if not conj_nsubj:         \n",
    "                    subtask = add_task(verb, task.nouns)\n",
    "                else:\n",
    "                    subtask = add_task(verb, conj_nsubj)\n",
    "                task.subtask = subtask\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            verb = add_verb(token, tag=\"ROOT\")\n",
    "            verb_data = [verb]  # Start with the root verb\n",
    "            actors_list = []\n",
    "\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"nsubj\":\n",
    "                    actor = add_actors(child)\n",
    "                    actors_list.append(actor)\n",
    "                    collect_subj_conjuncts(child, actors_list)\n",
    "\n",
    "            task = add_task(verb_data, actors_list)\n",
    "            all_tasks.append(task)\n",
    "            collect_conjuncts(token, task)\n",
    "\n",
    "    return all_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [waters, TAG: ROOT], Nouns: [A])\n",
      "Task(Verbs: [cleans, Prepositions: (Then, TAG: advmod), TAG: ROOT], Nouns: [B])\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Robot A waters the plants. Then Robot B cleans the room.\"\n",
    "\n",
    "\n",
    "doc = nlp(input_text)\n",
    "all_tasks = analyse_tree(doc)\n",
    "for i in all_tasks:\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_markers = [\"while\", \"as\", \"when\", \"whilst\"]\n",
    "after_completing_markers = [\"after\", \"then\", \"After\", \"Then\"]\n",
    "before_completing_markers = [\"before\"]\n",
    "choice_markers = [\"or\"]\n",
    "and_markers = [\"and\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x169b4e5d0>]\n",
      "defaultdict(<class 'list'>, {'Some_Actor': ['walk']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'Some_Actor': ['walk']})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_subtask_type(task):\n",
    "    if task.subtask is None:  \n",
    "        return None  \n",
    "\n",
    "    for verb in task.subtask.verbs:\n",
    "        if verb.preposition:  \n",
    "            return verb.preposition[0]  \n",
    "\n",
    "    return None \n",
    "\n",
    "def is_this_or(actor):\n",
    "    for p in actor.preposition:\n",
    "        if p.name == \"or\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_preposition_exist(words, prepositions):\n",
    "    for word in words:\n",
    "        for p in word.preposition:\n",
    "            if p.name in prepositions:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def print_names(actors):\n",
    "    s = \"\"\n",
    "    for a in actors:\n",
    "        s+= a.name+(\"_\")\n",
    "    return s\n",
    "\n",
    "\n",
    "#rules for created dictionary\n",
    "def get_parallel_tasks(doc):\n",
    "    order_cnt = 0\n",
    "    actors_actions = defaultdict(list)\n",
    "    all_tasks = analyse_tree(doc)\n",
    "    print(all_tasks)\n",
    "\n",
    "\n",
    "    for i, task in enumerate(all_tasks):\n",
    "        \n",
    "        #if task has a subsequencial mark\n",
    "        if is_preposition_exist(task.verbs, after_completing_markers):\n",
    "            prev_task = all_tasks[i-1]\n",
    "            unique_nouns = {}\n",
    "\n",
    "            for noun in task.nouns + prev_task.nouns:\n",
    "                unique_nouns[noun.name] = noun  \n",
    "            actors = list(unique_nouns.values())\n",
    "            if len(actors) > 1:\n",
    "                names_str = print_names(actors)\n",
    "                for actor in actors: \n",
    "                    actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))                           \n",
    "                order_cnt+=1\n",
    "            \n",
    "\n",
    "        #if task has subtask \n",
    "        subtask_prep = find_subtask_type(task)    \n",
    "        if (subtask_prep):\n",
    "            subtask = task.subtask\n",
    "\n",
    "            #parallel synchronized execution\n",
    "            if subtask_prep.name in parallel_markers:\n",
    "                \n",
    "                unique_nouns = {}\n",
    "                for noun in task.nouns + subtask.nouns:\n",
    "                    unique_nouns[noun.name] = noun  \n",
    "                actors = list(unique_nouns.values())\n",
    "\n",
    "                names_str = print_names(actors)\n",
    "                if len(actors) > 1:\n",
    "                    for actor in task.nouns:                                               \n",
    "                        actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                        for verb in task.verbs:\n",
    "                            actors_actions[actor.name].append(verb.name)\n",
    "                        actors_actions[actor.name].append(\"SINC_\"+ names_str + str(order_cnt))\n",
    "                    for actor in subtask.nouns:                                               \n",
    "                        actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                        for verb in subtask.verbs:\n",
    "                            actors_actions[actor.name].append(verb.name)\n",
    "                        actors_actions[actor.name].append(\"SINC_\"+ names_str + str(order_cnt))    \n",
    "                    order_cnt+=1\n",
    "                else: \n",
    "                    actor = task.nouns[0]\n",
    "                    for verb in task.verbs:\n",
    "                        actors_actions[actor.name].append(verb.name)\n",
    "                    for verb in subtask.verbs:\n",
    "                        actors_actions[actor.name].append(verb.name)\n",
    "                continue\n",
    "            \n",
    "            #direct order\n",
    "            #one action directly after another\n",
    "            if subtask_prep.name in after_completing_markers:\n",
    "                actors = list(set(task.nouns + subtask.nouns))\n",
    "                names_str = print_names(actors)\n",
    "                for actor in task.nouns:                                               \n",
    "                    actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                    for verb in task.verbs:\n",
    "                        actors_actions[actor.name].append(verb.name)\n",
    "                for actor in subtask.nouns:                                               \n",
    "                    actors_actions[actor.name].append(subtask.verbs[0].name)\n",
    "                    actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                order_cnt+=1\n",
    "                continue\n",
    "            \n",
    "            #direct order\n",
    "            #one action directly before another\n",
    "            if subtask_prep.name == \"before\":\n",
    "                actors = list(set(task.nouns + subtask.nouns))\n",
    "                names_str = print_names(actors)\n",
    "                for actor in task.nouns: \n",
    "                    for verb in task.verbs:\n",
    "                        actors_actions[actor.name].append(verb.name)\n",
    "                    actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))                          \n",
    "\n",
    "                for actor in subtask.nouns:                                               \n",
    "                    actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                    actors_actions[actor.name].append(subtask.verbs[0].name)\n",
    "                order_cnt+=1\n",
    "                continue\n",
    "\n",
    "        if len(task.nouns) > 1:\n",
    "            #has OR between verbs     \n",
    "            if (is_preposition_exist(task.verbs, choice_markers)):\n",
    "                verbs_str = print_names(task.verbs)\n",
    "                for actor in task.nouns:                             \n",
    "                    if actor.name not in actors_actions:\n",
    "                        actors_actions[actor.name].append(\"ORVERB_\"+ verbs_str  + str(order_cnt))                                  \n",
    "            else:        \n",
    "                for verb in task.verbs:\n",
    "                    #task choice\n",
    "                    if (is_preposition_exist(task.nouns, choice_markers)): #gather actors groups if there is OR \n",
    "                        actors_before = []\n",
    "                        groups = \"\"\n",
    "                        for actor in task.nouns:\n",
    "                            if actor.name not in actors_actions:\n",
    "                                actors_before.append(actor)\n",
    "                            if (is_this_or(actor)):\n",
    "                                if (is_preposition_exist(actors_before, and_markers)):\n",
    "                                    names_str = print_names(actors_before)\n",
    "                                    for a in actors_before:\n",
    "                                        actors_actions[a.name].append(\"ORNOUN_\" + names_str + str(order_cnt))\n",
    "                                        actors_actions[a.name].append(verb.name)\n",
    "                                else:\n",
    "                                    for a in actors_before:\n",
    "                                        actors_actions[a.name].append(\"ORNOUN_\" + a.name + \"_\" + str(order_cnt))\n",
    "                                        actors_actions[a.name].append(verb.name) \n",
    "                                actors_before = []                           \n",
    "                        names_str = print_names(actors_before)\n",
    "                        for a in actors_before:\n",
    "                            actors_actions[a.name].append(\"ORNOUN_\" + names_str + str(order_cnt))\n",
    "                            actors_actions[a.name].append(verb.name)\n",
    "                        print(groups)\n",
    "                        order_cnt+=1\n",
    "\n",
    " \n",
    "                    #no choice\n",
    "                    else:\n",
    "                        names_str = print_names(task.nouns)\n",
    "                        for actor in task.nouns:                                               \n",
    "                            actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                            actors_actions[actor.name].append(verb.name)\n",
    "                            actors_actions[actor.name].append(\"SINC_\"+ names_str + str(order_cnt))\n",
    "                        order_cnt+=1\n",
    "        else:\n",
    "            if (is_preposition_exist(task.verbs, choice_markers)):\n",
    "                verbs_str = print_names(task.verbs)\n",
    "                for actor in task.nouns:                             \n",
    "                    if actor.name not in actors_actions:\n",
    "                        actors_actions[actor.name] = []\n",
    "                        actors_actions[actor.name].append(\"ORVERB_\"+ verbs_str  + str(order_cnt))\n",
    "            else:\n",
    "                actor = task.nouns[0]\n",
    "                for verb in task.verbs:\n",
    "                    actors_actions[actor.name].append(verb.name)\n",
    "    print(actors_actions)\n",
    "    return actors_actions\n",
    "\n",
    "input_text =\"Robot A, Robot B and Robot C walk.\"\n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Bob waters the plants, before Anna cleans the room. Anna jumps.\"\n",
    " \n",
    "doc = nlp(input_text)\n",
    "\n",
    "\n",
    "\n",
    "coref_map = {}\n",
    "\n",
    "#for chain in doc._.coref_chains:\n",
    "#    main_ref = chain.main.text\n",
    "#\n",
    "#    for mention in chain.mentions:\n",
    "#        mention_text = mention.text\n",
    "#        if mention_text.lower() != main_ref.lower():  \n",
    "#            coref_map[mention_text] = main_ref\n",
    "\n",
    "#print(coref_map)\n",
    "                \n",
    "#get_parallel_tasks(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x1793d62d0>, <__main__.Task object at 0x17871d9a0>]\n",
      "defaultdict(<class 'list'>, {'Bob': ['waters', 'BARRIER_Bob_Anna_0'], 'Anna': ['BARRIER_Bob_Anna_0', 'cleans', 'jumps']})\n",
      "✅ Petri net saved as petri_net.png\n"
     ]
    }
   ],
   "source": [
    "def transition_exists(net, name):\n",
    "    try:\n",
    "        net.transition(name)  # Try to retrieve the transition\n",
    "        return True  \n",
    "    except ConstraintError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def place_exists(net, name):\n",
    "    try:\n",
    "        net.place(name)  # Try to retrieve the transition\n",
    "        return True  \n",
    "    except ConstraintError:\n",
    "        return False\n",
    "\n",
    "def extract_brenching(text):\n",
    "    pattern = r\"ORVERB_([a-zA-Z_]+(?:_[a-zA-Z_]+)*)_\"\n",
    "    words = re.findall(pattern, text)\n",
    "    return words[0].split('_') if words else []\n",
    "\n",
    "def extract_ornoun(text):\n",
    "    pattern = r\"^(ORNOUN)_([^_]+(?:_[^_]+)*)_([^_]+)$\"  # Captures middle and last parts\n",
    "    match = re.match(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        final_part = f\"{match.group(1)}_{match.group(3)}\"  # ORNOUN_ + last word\n",
    "        middle_part = match.group(2)  # The middle words\n",
    "        return final_part, middle_part\n",
    "    return None, None  # Return None if no match is found\n",
    "\n",
    "\n",
    "def draw_petri_net(actors_actions):\n",
    "    n = PetriNet('petri_net')\n",
    "    n.add_place(Place('start'))\n",
    "    n.add_transition(Transition('task_start'))\n",
    "    n.add_input('start', 'task_start', Value(\"1\"))\n",
    "    \n",
    "    n.add_place(Place('end'))\n",
    "    n.add_transition(Transition('task_end'))\n",
    "    n.add_output('end', \"task_end\", Value(\"1\"))\n",
    "\n",
    "\n",
    "    for actor in actors_actions.keys():\n",
    "        #start place and transition\n",
    "        n.add_place(Place(actor+str(-1), \"Robot is on\"))\n",
    "        previous_place = actor+str(-1)\n",
    "        n.add_output(actor+str(-1), 'task_start', Value(\"1\"))\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(actors_actions[actor]):\n",
    "            verb = actors_actions[actor][i]\n",
    "            \n",
    "            #for sequential\n",
    "            if not verb.startswith((\"BARRIER_\", \"SINC_\", \"OR\")):\n",
    "                n.add_transition(Transition(verb+'_'+actor+'_'+str(i)))\n",
    "            \n",
    "                n.add_input(previous_place, verb+'_'+actor+'_'+str(i), Value(\"1\"))\n",
    "                n.add_place(Place(actor+str(i)))\n",
    "                n.add_output(actor+str(i), verb+'_'+actor+'_'+str(i), Value(\"1\"))\n",
    "                \n",
    "                previous_place = actor+str(i)\n",
    "                    \n",
    "            else:\n",
    "            #for barriers\n",
    "                if verb.startswith((\"BARRIER_\")):\n",
    "                    if not transition_exists(n, verb):\n",
    "                        n.add_transition(Transition(verb))\n",
    "                    n.add_input(previous_place, verb, Value(\"1\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), verb, Value(\"1\"))\n",
    "                    previous_place = actor+str(i)                    \n",
    "        \n",
    "\n",
    "                if verb.startswith((\"SINC_\")):    \n",
    "                    verb = actors_actions[actor][i]\n",
    "                    if not transition_exists(n, verb):\n",
    "                        n.add_transition(Transition(verb))\n",
    "                    n.add_input(previous_place, verb, Value(\"1\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), verb, Value(\"1\"))\n",
    "                    previous_place = actor+str(i)           \n",
    "                    \n",
    "                    \n",
    "                #for OR between verbs\n",
    "                if verb.startswith((\"ORVERB_\")):\n",
    "                    #ORVERB_take_wash_0\n",
    "                    brenches = extract_brenching(verb)\n",
    "                    print(brenches)\n",
    "\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    for b in brenches:\n",
    "                        transition_name = b+'_'+actor+'_'+str(i)\n",
    "                        n.add_transition(Transition(transition_name))\n",
    "                        n.add_input(previous_place, transition_name, Value(\"1\"))\n",
    "                        n.add_output(actor+str(i), transition_name, Value(\"1\"))\n",
    "                    \n",
    "                    previous_place = actor+str(i)  \n",
    "                \n",
    "                #for OR between nouns\n",
    "                if verb.startswith((\"ORNOUN_\")):    \n",
    "                    print(\"hehehe\")\n",
    "                    transition_name, actors_name = extract_ornoun(verb)\n",
    "                    print(transition_name)\n",
    "                    if not transition_exists(n, transition_name):\n",
    "                        n.add_transition(Transition(transition_name))\n",
    "                        n.add_place(Place(\"PLACE_\"+transition_name))\n",
    "                        n.add_output(\"PLACE_\"+transition_name, transition_name, Value(\"1\"))\n",
    "                    n.add_input(previous_place, transition_name, Value(\"1\"))\n",
    "                    previous_place = \"PLACE_\"+transition_name\n",
    "                    i+=1\n",
    "                    verb = actors_actions[actor][i]\n",
    "                    transition_name_2 = verb+'_'+actors_name+'_'+str(i)\n",
    "                    if not transition_exists(n, transition_name_2):\n",
    "                        n.add_transition(Transition(transition_name_2))\n",
    "                        n.add_input(previous_place, transition_name_2, Value(\"1\"))\n",
    "                    \n",
    "                        place_name=\"PLACE_\"+transition_name+'2'\n",
    "                        if not place_exists(n, place_name):\n",
    "                            n.add_place(Place(place_name))\n",
    "                            n.add_transition(Transition(transition_name+'2'))\n",
    "                            n.add_input(place_name, transition_name+'2', Value(\"1\"))\n",
    "                        n.add_output(place_name, transition_name_2, Value(\"1\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), transition_name+'2', Value(\"1\"))\n",
    "                    previous_place = actor+str(i)\n",
    "                    \n",
    "                                       \n",
    "                    \n",
    "            if i == len(actors_actions[actor]) - 1:\n",
    "                n.add_input(previous_place, 'task_end', Value(\"ε\"))     \n",
    "            \n",
    "            i += 1           \n",
    "\n",
    "    filename = \"petri_net.png\"\n",
    "    n.draw(filename)\n",
    "    print(f\"✅ Petri net saved as {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "#input_text = \"Mary, Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark walk.\"\n",
    "#input_text = \"Robot A and Robot B, or Robot A and Robot C walk.\"\n",
    "#input_text = \"Robot A is running. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A and Robot B take the pan or washes it\"\n",
    "doc = nlp(input_text)\n",
    "input = get_parallel_tasks(doc)  \n",
    "draw_petri_net(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(['node_0', 'node_1'], [])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = PetriNet('ggg')\n",
    "n.add_place(Place('start', [0]))\n",
    "n.add_transition(Transition('t', Expression('x<5')))\n",
    "n.add_input('start', 't', Variable('x'))\n",
    "n.add_output('start', 't', Expression('x+1'))\n",
    "n.draw(\"value-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x17871db50>]\n",
      "defaultdict(<class 'list'>, {'Some_Actor': ['Mary']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'Some_Actor': ['Mary']})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "#OR cases\n",
    "\n",
    "#successful\n",
    "#input_text = \"Mary and Ben or Mark and John walk.\"\n",
    "input_text = \"Mary, Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark walk.\"\n",
    "#input_text = \"Robot A and Robot B, or Robot A and Robot C walk.\"\n",
    "#input_text = \"Robot A is running. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A and Robot B take the pan or washes it\"\n",
    "\n",
    " \n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [draw, TAG: ROOT], Nouns: [Anna])\n",
      "[<__main__.Task object at 0x178747cb0>]\n",
      "defaultdict(<class 'list'>, {'Anna': ['draw']})\n",
      "defaultdict(<class 'list'>, {'Anna': ['draw']})\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robots A and Robot C help each other\"\n",
    "#input_text = \"Robot A takes the pan, Robot B takes the pencil.\"\n",
    "#input_text = \"Robot A takes the pan and drops it. \"\n",
    "#input_text = \"Robot A, Robot B and Robot C takes the pan, Robot B takes the pencil\"\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robot A and Robot C work together and Robot B is cleaning\"\n",
    "#input_text = \"Robot A is running, then swiming. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A, Robot B and Robot C take the pan and wash it\"\n",
    "#input_text = \"Robot A and Robot B take the pan or wash it\"\n",
    "\n",
    "\n",
    "#WEIRD BEHAVIOUR in spacy\n",
    "#input_text = \"Robots A and Robot C help each other and Robot B is cleaning\"\n",
    "#input_text = \"Robots A and Robot C help each other, Robot B cleans\"\n",
    "\n",
    "#input_text = \"Robot A goes.\"\n",
    "#input_text = \"Robot G moves its arm while analyzing the object.\"\n",
    "#input_text = \"Robot A and Robot B take the pan or wash it\"\n",
    "#input_text = \"Bob waters the plants, while Anna cleans the room.\"\n",
    "#input_text = \"Robot A, Robot B and Robot C take the pan and wash it\"\n",
    "#input_text = \"Robot A, Robot B and Robot C take the pan and wash it\"\n",
    "\n",
    "#input_text = \"Robot A and B, take the pot. After Robot C put the tomato in the pot.\"\n",
    "input_text = \" Anna draw the line Bob wipe the line off.\"\n",
    "\n",
    "doc = nlp(input_text)\n",
    "all_tasks = analyse_tree(doc)\n",
    "for i in all_tasks:\n",
    "    print(i)\n",
    "\n",
    "print(get_parallel_tasks(doc))\n",
    "\n",
    "#options={\"compact\": True, \"distance\":60}\n",
    "#spacy.displacy.serve(doc, style=\"dep\", auto_select_port=True)\n",
    "#print_tasks(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x17871c890>]\n",
      "defaultdict(<class 'list'>, {'Some_Actor': ['Grab', 'lift', 'put', 'holding']})\n",
      "✅ Petri net saved as petri_net.png\n"
     ]
    }
   ],
   "source": [
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robots A and Robot C help each other\"\n",
    "#input_text = \"Robot A takes the pan, Robot B takes the pencil.\"\n",
    "#input_text = \"Robot A takes the pan and drops it. \"\n",
    "#input_text = \"Robot A, Robot B and Robot C takes the pan, Robot B takes the pencil\"\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robot A and Robot C work together and Robot B is cleaning\"\n",
    "#input_text = \"Robot A is running, then swiming. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A, Robot B and Robot C take the pan and wash it\"\n",
    "#input_text = \"Robot A and Robot B take the pan or wash it\"\n",
    "#input_text = \"Robot A takes the pan or washes it\"\n",
    "#input_text = \"Robot A and Robot B take the pan or wash it\"\n",
    "\n",
    "\n",
    "#input_text = \"Robot A and B, take the pot, after Robot C put the tomato in the pot.\"\n",
    "#input_text = \"Robot A and B, take the pot. After that, Robot C put the tomato in the pot.\"\n",
    "input_text = \"Grab the pot, lift it up in the air and put the tomato inside while holding it up.\"\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp(input_text)\n",
    "input = get_parallel_tasks(doc)  \n",
    "draw_petri_net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dependency_tree_as_svg(doc, filename=\"dependency_tree.svg\"):\n",
    "    svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "    if not svg:\n",
    "        raise ValueError(\"Error: displacy.render() returned None.\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(svg)\n",
    "    print(f\"✅ Dependency tree saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependency tree saved as dependency_tree.svg\n",
      "Task(Verbs: [Open, TAG: ROOT, grab, Prepositions: (and, TAG: cc), TAG: conj, take, TAG: conj], Nouns: [Some_Actor, None])\n",
      "[<__main__.Task object at 0x1793d55e0>]\n",
      "defaultdict(<class 'list'>, {'Some_Actor': ['Open', 'grab', 'take']})\n",
      "✅ Petri net saved as petri_net.png\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "##################### TEST #########################\n",
    "####################################################\n",
    "\n",
    "\n",
    "input_text = \"\" \\\n",
    "\"Open the box, grab the teddy bear, and take it out.\"\n",
    "doc = nlp(input_text)\n",
    "save_dependency_tree_as_svg(doc)\n",
    "\n",
    "all_tasks = analyse_tree(doc)\n",
    "for i in all_tasks:\n",
    "    print(i)\n",
    "\n",
    "input = get_parallel_tasks(doc)  \n",
    "draw_petri_net(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetriNetApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.geometry(\"800x600\")  \n",
    "\n",
    "        self.entry = tk.Entry(root, width=60, font=(\"Arial\", 14), bd=3, relief=\"solid\")\n",
    "        self.entry.pack(pady=20)\n",
    "\n",
    "        self.button = tk.Button(root, text=\"Draw Petri Net\", command=self.on_button_click)\n",
    "        self.button.pack(pady=5)\n",
    "\n",
    "        self.output_label = tk.Label(root, text=\"\", font=(\"Arial\", 12))\n",
    "        self.output_label.pack(pady=20)\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def on_button_click(self):\n",
    "        input_text = self.entry.get()\n",
    "        self.present_output(input_text)\n",
    "\n",
    "    def present_output(self, input_text):\n",
    "        doc = nlp(input_text)  \n",
    "        input_data = get_parallel_tasks(doc)\n",
    "\n",
    "        self.save_dependency_tree(doc) \n",
    "        \n",
    "        draw_petri_net(input_data)\n",
    "\n",
    "        output = \"Petri Net created.\\n\"\n",
    "        current_text = self.output_label.cget(\"text\")\n",
    "        self.output_label.config(text=current_text + output)\n",
    "\n",
    "         \n",
    "\n",
    "    def save_dependency_tree(self, doc, filename=\"dependency_tree.svg\"):\n",
    "        svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "        if not svg or not isinstance(svg, str):\n",
    "            output = \"Error: displacy.render() returned None.\\n\"\n",
    "            current_text = self.output_label.cget(\"text\")\n",
    "            self.output_label.config(text=current_text + output)\n",
    "            raise ValueError(\"Error: displacy.render() returned None.\")\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(svg)\n",
    "\n",
    "        output = f\"Dependency tree saved as {filename}.\\n\"\n",
    "        current_text = self.output_label.cget(\"text\")\n",
    "        self.output_label.config(text=current_text + output)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x178747d40>]\n",
      "defaultdict(<class 'list'>, {'Some_Actor': ['jump']})\n",
      "✅ Petri net saved as petri_net.png\n",
      "[<__main__.Task object at 0x17871f8f0>]\n",
      "defaultdict(<class 'list'>, {'Ann': ['BARRIER_Ann_Bob_0', 'jumping', 'SINC_Ann_Bob_0'], 'Bob': ['BARRIER_Ann_Bob_0', 'jumping', 'SINC_Ann_Bob_0']})\n",
      "✅ Petri net saved as petri_net.png\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "app = PetriNetApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

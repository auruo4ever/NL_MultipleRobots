{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import threading \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import snakes.plugins\n",
    "snakes.plugins.load(\"gv\", \"snakes.nets\", \"nets\")\n",
    "from nets import *\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_words = {\"and\", \"both\", \"along with\", \"as well as\", \"in conjunction with\", \"together with\"}\n",
    "individual_words = {\"or\", \"either\", \"one of\", \"neither\", \"nor\", \"any of\", \"each of\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [places, moves], Nouns: [table, (on), chair, None])\n"
     ]
    }
   ],
   "source": [
    "#Entities\n",
    "class Preposition:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.name})\"\n",
    "    \n",
    "    \n",
    "class Verb:\n",
    "    def __init__(self, name, preposition=None):\n",
    "        self.name = name\n",
    "        self.preposition = preposition if isinstance(preposition, list) else [preposition]\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.preposition:\n",
    "            p = ', '.join(str(p) for p in self.preposition)\n",
    "            return f\"{self.name}, {p}\"\n",
    "        else:\n",
    "            return f\"{self.name}\"\n",
    "    \n",
    "\n",
    "class Noun:\n",
    "    def __init__(self, name, preposition=None):\n",
    "        self.name = name\n",
    "        self.preposition = preposition if isinstance(preposition, list) else [preposition]\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.preposition:\n",
    "            p = ', '.join(str(p) for p in self.preposition)\n",
    "            return f\"{self.name}, {p}\"\n",
    "        else:\n",
    "            return f\"{self.name}\"\n",
    "\n",
    "    \n",
    "class Task:\n",
    "    def __init__(self, verbs, nouns):\n",
    "        self.verbs = verbs if isinstance(verbs, list) else [verbs] \n",
    "        self.nouns = nouns if isinstance(nouns, list) else [nouns]\n",
    "    def __str__(self):\n",
    "        verb_str = ', '.join(str(verbs) for verbs in self.verbs)\n",
    "        nouns_str = ', '.join(str(noun) for noun in self.nouns)\n",
    "        return f\"Task(Verbs: [{verb_str}], Nouns: [{nouns_str}])\"\n",
    "    \n",
    "    def get_all_actors(self):\n",
    "        actors = []\n",
    "        for noun in self.nouns:\n",
    "            actors.extend(noun.name)  \n",
    "        return actors\n",
    "\n",
    "\n",
    "preposition1 = Preposition(\"on\")\n",
    "noun1 = Noun(\"table\", preposition1)\n",
    "noun2 = Noun(\"chair\")\n",
    "\n",
    "# Create a list of verbs\n",
    "verbs = Task([\"places\", \"moves\"], [noun1, noun2])\n",
    "\n",
    "# Print out the verb and its related nouns and prepositions\n",
    "print(verbs)  # Output: Verb(places, moves, Noun(table, floor, Preposition(on)), Noun(chair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_tree(doc):\n",
    "\n",
    "    all_tasks = []\n",
    "\n",
    "    def add_actors(subj):\n",
    "        prepositions = []\n",
    "        collect_prepositions(subj, prepositions)\n",
    "        actor = Noun(subj.text, prepositions)\n",
    "        return actor\n",
    "    \n",
    "    def add_task(verbs, actors):\n",
    "        task = Task(verbs, actors)\n",
    "        return task\n",
    "    \n",
    "    def add_verb(verb):\n",
    "        prepositions = []\n",
    "        collect_prepositions(verb, prepositions)\n",
    "        verb1 = Verb(verb.text, prepositions)\n",
    "        return verb1\n",
    "\n",
    "    def collect_subj_conjuncts(subj, actors):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"conj\":\n",
    "                actor = add_actors(child)\n",
    "                actors.append(actor)\n",
    "                collect_subj_conjuncts(child, actors)\n",
    "    \n",
    "    def collect_prepositions(subj, prepositions):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"cc\":\n",
    "                preposition = Preposition(child.text)\n",
    "                prepositions.append(preposition)\n",
    "\n",
    "\n",
    "    def collect_conjuncts(verb, root_subject, verb_data):\n",
    "        for child in verb.children:\n",
    "            if child.dep_ == \"conj\" and child.pos_ == \"VERB\":\n",
    "                conj_nsubj = []\n",
    "\n",
    "                # Check if the conjunct verb has its own subject\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ == \"nsubj\":\n",
    "                        actor = add_actors(grandchild)\n",
    "                        conj_nsubj.append(actor)\n",
    "                        collect_subj_conjuncts(grandchild, conj_nsubj)\n",
    "\n",
    "                # If no subject for the conjunct verb, add it to the root's verb_data\n",
    "                if not conj_nsubj:\n",
    "                    verb = add_verb(child)\n",
    "                    verb_data.append(verb) \n",
    "                else:\n",
    "                    verb = add_verb(child)\n",
    "                    task = add_task(verb, conj_nsubj)\n",
    "                    all_tasks.append(task)\n",
    "\n",
    "                collect_conjuncts(child, root_subject, verb_data)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            verb = add_verb(token)\n",
    "            verb_data = [verb]  # Start with the root verb\n",
    "            actors_list = []\n",
    "\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"nsubj\":\n",
    "                    actor = add_actors(child)\n",
    "                    actors_list.append(actor)\n",
    "                    collect_subj_conjuncts(child, actors_list)\n",
    "\n",
    "            task = add_task(verb_data, actors_list)\n",
    "            all_tasks.append(task)\n",
    "            collect_conjuncts(token, actors_list, verb_data)\n",
    "\n",
    "    return all_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x162507f10>]\n",
      "{'A': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'B': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'C': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'],\n",
       " 'B': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'],\n",
       " 'C': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_or_exist(words):\n",
    "    for word in words:\n",
    "        for p in word.preposition:\n",
    "            if p.name == \"or\":\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_this_or(actor):\n",
    "    for p in actor.preposition:\n",
    "        if p.name == \"or\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_and_exist(actors):\n",
    "    for actor in actors:\n",
    "        for p in actor.preposition:\n",
    "            if p.name == \"and\":\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def print_names(actors):\n",
    "    s = \"\"\n",
    "    for a in actors:\n",
    "        s+= a.name+(\"_\")\n",
    "    return s\n",
    "\n",
    "#rules for created dictionary\n",
    "def get_parallel_tasks(doc):\n",
    "    order_cnt = 0\n",
    "    actors_actions = {}\n",
    "    all_tasks = analyse_tree(doc)\n",
    "    print(all_tasks)\n",
    "\n",
    "    for task in all_tasks:\n",
    "        if len(task.nouns) > 1:\n",
    "            if (is_or_exist(task.verbs)):\n",
    "                verbs_str = print_names(task.verbs)\n",
    "                for actor in task.nouns:                             \n",
    "                    if actor.name not in actors_actions:\n",
    "                        actors_actions[actor.name] = []\n",
    "                        actors_actions[actor.name].append(\"ORVERB_\"+ verbs_str  + str(order_cnt))\n",
    "                    \n",
    "            else:        \n",
    "                for verb in task.verbs:\n",
    "                    #task choice\n",
    "                    if (is_or_exist(task.nouns)): #gather actors groups if there is OR \n",
    "                        actors_before = []\n",
    "                        groups = \"\"\n",
    "                        for actor in task.nouns:\n",
    "                            if actor.name not in actors_actions:\n",
    "                                actors_actions[actor.name] = []\n",
    "                                actors_before.append(actor)\n",
    "                            if (is_this_or(actor)):\n",
    "                                if (is_and_exist(actors_before)):\n",
    "                                    names_str = print_names(actors_before)\n",
    "                                    for a in actors_before:\n",
    "                                        actors_actions[a.name].append(\"ORNOUN_\" + names_str + str(order_cnt))\n",
    "                                        actors_actions[a.name].append(verb.name)\n",
    "                                else:\n",
    "                                    for a in actors_before:\n",
    "                                        actors_actions[a.name].append(\"ORNOUN_\" + a.name + \"_\" + str(order_cnt))\n",
    "                                        actors_actions[a.name].append(verb.name) \n",
    "                                actors_before = []                           \n",
    "                        names_str = print_names(actors_before)\n",
    "                        for a in actors_before:\n",
    "                            actors_actions[a.name].append(\"ORNOUN_\" + names_str + str(order_cnt))\n",
    "                            actors_actions[a.name].append(verb.name)\n",
    "                        print(groups)\n",
    "                        order_cnt+=1\n",
    "                        \n",
    "                    #no choice\n",
    "                    else:\n",
    "                        for actor in task.nouns:                                               \n",
    "                            if actor.name not in actors_actions:\n",
    "                                actors_actions[actor.name] = []\n",
    "                            names_str = print_names(task.nouns)\n",
    "                            actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                            actors_actions[actor.name].append(verb.name)\n",
    "                            actors_actions[actor.name].append(\"SINC_\"+ names_str + str(order_cnt))\n",
    "                        order_cnt+=1\n",
    "        else:\n",
    "            actor = task.nouns[0]\n",
    "            if actor.name not in actors_actions:\n",
    "                    actors_actions[actor.name] = []\n",
    "            for verb in task.verbs:\n",
    "                    actors_actions[actor.name].append(verb.name)\n",
    "    print(actors_actions)\n",
    "    return actors_actions\n",
    "\n",
    "input_text =\"Robot A, Robot B and Robot C walk.\"\n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x1624bf710>]\n",
      "{'A': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'B': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'C': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0']}\n"
     ]
    }
   ],
   "source": [
    "def transition_exists(net, name):\n",
    "    try:\n",
    "        net.transition(name)  # Try to retrieve the transition\n",
    "        return True  \n",
    "    except ConstraintError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def place_exists(net, name):\n",
    "    try:\n",
    "        net.place(name)  # Try to retrieve the transition\n",
    "        return True  \n",
    "    except ConstraintError:\n",
    "        return False\n",
    "\n",
    "def extract_brenching(text):\n",
    "    pattern = r\"ORVERB_([a-zA-Z_]+(?:_[a-zA-Z_]+)*)_\"\n",
    "    words = re.findall(pattern, text)\n",
    "    return words[0].split('_') if words else []\n",
    "\n",
    "def extract_ornoun(text):\n",
    "    pattern = r\"^(ORNOUN)_([^_]+(?:_[^_]+)*)_([^_]+)$\"  # Captures middle and last parts\n",
    "    match = re.match(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        final_part = f\"{match.group(1)}_{match.group(3)}\"  # ORNOUN_ + last word\n",
    "        middle_part = match.group(2)  # The middle words\n",
    "        return final_part, middle_part\n",
    "    return None, None  # Return None if no match is found\n",
    "\n",
    "\n",
    "def draw_petri_net(actors_actions):\n",
    "    n = PetriNet('new')\n",
    "    n.add_place(Place('start'))\n",
    "    n.add_transition(Transition('task_start'))\n",
    "    n.add_input('start', 'task_start', Value(\"ε\"))\n",
    "    \n",
    "    n.add_place(Place('end'))\n",
    "    n.add_transition(Transition('task_end'))\n",
    "    n.add_output('end', \"task_end\", Value(\"ε\"))\n",
    "\n",
    "\n",
    "    for actor in actors_actions.keys():\n",
    "        #start place and transition\n",
    "        n.add_place(Place(actor+str(-1), \"Robot is on\"))\n",
    "        previous_place = actor+str(-1)\n",
    "        n.add_output(actor+str(-1), 'task_start', Value(\"ε\"))\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(actors_actions[actor]):\n",
    "            verb = actors_actions[actor][i]\n",
    "            \n",
    "            #for sequential\n",
    "            if not verb.startswith((\"BARRIER_\", \"SINC_\", \"OR\")):\n",
    "                n.add_transition(Transition(verb+'_'+actor+'_'+str(i)))\n",
    "            \n",
    "                n.add_input(previous_place, verb+'_'+actor+'_'+str(i), Value(\"ε\"))\n",
    "                n.add_place(Place(actor+str(i)))\n",
    "                n.add_output(actor+str(i), verb+'_'+actor+'_'+str(i), Value(\"ε\"))\n",
    "                \n",
    "                previous_place = actor+str(i)\n",
    "                    \n",
    "            else:\n",
    "            #for barriers\n",
    "                if verb.startswith((\"BARRIER_\")):\n",
    "                    if not transition_exists(n, verb):\n",
    "                        n.add_transition(Transition(verb))\n",
    "                    n.add_input(previous_place, verb, Value(\"ε\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), verb, Value(\"e\"))\n",
    "                    previous_place = actor+str(i)\n",
    "                    i+=1\n",
    "                    \n",
    "                    verb = actors_actions[actor][i]\n",
    "                    transition_name = verb+'_'+actor+'_'+str(i)\n",
    "                    n.add_transition(Transition(transition_name))\n",
    "                    n.add_input(previous_place, transition_name, Value(\"ε\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), transition_name, Value(\"h\"))\n",
    "                    previous_place = actor+str(i)\n",
    "                    \n",
    "                    i+=1\n",
    "                    verb = actors_actions[actor][i]\n",
    "                    if not transition_exists(n, verb):\n",
    "                        n.add_transition(Transition(verb))\n",
    "                    n.add_input(previous_place, verb, Value(\"ε\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), verb, Value(\"ε\"))\n",
    "                    previous_place = actor+str(i)           \n",
    "                    \n",
    "\n",
    "                    ############ transition + circle with next action\n",
    "                    \n",
    "                #for OR between verbs\n",
    "                if verb.startswith((\"ORVERB_\")):\n",
    "                    #ORVERB_take_wash_0\n",
    "                    brenches = extract_brenching(verb)\n",
    "                    print(brenches)\n",
    "\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    for b in brenches:\n",
    "                        transition_name = b+'_'+actor+'_'+str(i)\n",
    "                        n.add_transition(Transition(transition_name))\n",
    "                        n.add_input(previous_place, transition_name, Value(\"ε\"))\n",
    "                        n.add_output(actor+str(i), transition_name, Value(\"h\"))\n",
    "                    \n",
    "                    previous_place = actor+str(i)  \n",
    "                \n",
    "                #for OR between nouns\n",
    "                if verb.startswith((\"ORNOUN_\")):    \n",
    "                    print(\"hehehe\")\n",
    "                    transition_name, actors_name = extract_ornoun(verb)\n",
    "                    print(transition_name)\n",
    "                    if not transition_exists(n, transition_name):\n",
    "                        n.add_transition(Transition(transition_name))\n",
    "                        n.add_place(Place(\"PLACE_\"+transition_name))\n",
    "                        n.add_output(\"PLACE_\"+transition_name, transition_name, Value(\"e\"))\n",
    "                    n.add_input(previous_place, transition_name, Value(\"ε\"))\n",
    "                    previous_place = \"PLACE_\"+transition_name\n",
    "                    i+=1\n",
    "                    verb = actors_actions[actor][i]\n",
    "                    transition_name_2 = verb+'_'+actors_name+'_'+str(i)\n",
    "                    if not transition_exists(n, transition_name_2):\n",
    "                        n.add_transition(Transition(transition_name_2))\n",
    "                        n.add_input(previous_place, transition_name_2, Value(\"h\"))\n",
    "                    \n",
    "                        place_name=\"PLACE_\"+transition_name+'2'\n",
    "                        if not place_exists(n, place_name):\n",
    "                            n.add_place(Place(place_name))\n",
    "                            n.add_transition(Transition(transition_name+'2'))\n",
    "                            n.add_input(place_name, transition_name+'2', Value(\"ε\"))\n",
    "                        n.add_output(place_name, transition_name_2, Value(\"e\"))\n",
    "                    n.add_place(Place(actor+str(i)))\n",
    "                    n.add_output(actor+str(i), transition_name+'2', Value(\"e\"))\n",
    "                    previous_place = actor+str(i)\n",
    "                    \n",
    "                                       \n",
    "                    \n",
    "            if i == len(actors_actions[actor]) - 1:\n",
    "                n.add_input(previous_place, 'task_end', Value(\"ε\"))     \n",
    "            \n",
    "            i += 1           \n",
    "\n",
    "    \n",
    "    n.draw(\"new.png\")\n",
    "\n",
    "\n",
    "#input_text = \"Mary, Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark walk.\"\n",
    "#input_text = \"Robot A and Robot B, or Robot A and Robot C walk.\"\n",
    "#input_text = \"Robot A is running. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A and Robot B take the pan or washes it\"\n",
    "doc = nlp(input_text)\n",
    "input = get_parallel_tasks(doc)  \n",
    "draw_petri_net(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(['node_0', 'node_1'], [])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = PetriNet('ggg')\n",
    "n.add_place(Place('start', [0]))\n",
    "n.add_transition(Transition('t', Expression('x<5')))\n",
    "n.add_input('start', 't', Variable('x'))\n",
    "n.add_output('start', 't', Expression('x+1'))\n",
    "n.draw(\"value-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x17ab6d710>]\n",
      "\n",
      "{'Mary': ['ORNOUN_Mary_0', 'walk'], 'Ben': ['ORNOUN_Ben_0', 'walk'], 'Mark': ['ORNOUN_Mark_John_0', 'walk'], 'John': ['ORNOUN_Mark_John_0', 'walk']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Mary': ['ORNOUN_Mary_0', 'walk'],\n",
       " 'Ben': ['ORNOUN_Ben_0', 'walk'],\n",
       " 'Mark': ['ORNOUN_Mark_John_0', 'walk'],\n",
       " 'John': ['ORNOUN_Mark_John_0', 'walk']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "#OR cases\n",
    "\n",
    "#successful\n",
    "#input_text = \"Mary and Ben or Mark and John walk.\"\n",
    "input_text = \"Mary, Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark walk.\"\n",
    "#input_text = \"Robot A and Robot B, or Robot A and Robot C walk.\"\n",
    "#input_text = \"Robot A is running. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A and Robot B take the pan or washes it\"\n",
    "\n",
    " \n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [take, (or), wash], Nouns: [A, (and), B])\n",
      "[<__main__.Task object at 0x17ab6ee10>]\n",
      "{'A': ['ORVERB_take_wash_0'], 'B': ['ORVERB_take_wash_0']}\n",
      "{'A': ['ORVERB_take_wash_0'], 'B': ['ORVERB_take_wash_0']}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robots A and Robot C help each other\"\n",
    "#input_text = \"Robot A takes the pan, Robot B takes the pencil.\"\n",
    "#input_text = \"Robot A takes the pan and drops it. \"\n",
    "#input_text = \"Robot A, Robot B and Robot C takes the pan, Robot B takes the pencil\"\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robot A and Robot C work together and Robot B is cleaning\"\n",
    "#input_text = \"Robot A is running, then swiming. Robot B is jumping. Robot C is singing.\"\n",
    "#input_text = \"Robot A, Robot B and Robot C take the pan and wash it\"\n",
    "input_text = \"Robot A and Robot B take the pan or wash it\"\n",
    "\n",
    "\n",
    "#WEIRD BEHAVIOUR in spacy\n",
    "#input_text = \"Robots A and Robot C help each other and Robot B is cleaning\"\n",
    "#input_text = \"Robots A and Robot C help each other, Robot B cleans\"\n",
    "\n",
    "#input_text = \"Robot A goes.\"\n",
    "\n",
    "doc = nlp(input_text)\n",
    "all_tasks = analyse_tree(doc)\n",
    "for i in all_tasks:\n",
    "    print(i)\n",
    "\n",
    "print(get_parallel_tasks(doc))\n",
    "\n",
    "#options={\"compact\": True, \"distance\":60}\n",
    "#spacy.displacy.serve(doc, style=\"dep\", auto_select_port=True)\n",
    "#print_tasks(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetriNetApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Petri Net Drawer\")\n",
    "\n",
    "        self.entry = tk.Entry(root, width=50)\n",
    "        self.entry.pack(pady=10)\n",
    "\n",
    "        self.button = tk.Button(root, text=\"Draw Petri Net\", command=self.on_button_click)\n",
    "        self.button.pack(pady=5)\n",
    "\n",
    "        self.canvas_frame = tk.Frame(root)\n",
    "        self.canvas_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.canvas_frame)\n",
    "        self.canvas.pack(side=\"left\", expand=True, fill=\"both\")\n",
    "\n",
    "        self.scrollbar_y = tk.Scrollbar(self.canvas_frame, orient=\"vertical\", command=self.canvas.yview)\n",
    "        self.scrollbar_y.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "        self.scrollbar_x = tk.Scrollbar(self.canvas_frame, orient=\"horizontal\", command=self.canvas.xview)\n",
    "        self.scrollbar_x.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "        self.canvas.config(yscrollcommand=self.scrollbar_y.set, xscrollcommand=self.scrollbar_x.set)\n",
    "\n",
    "    def on_button_click(self):\n",
    "        if not self.entry.winfo_exists():  #ensure widget exists\n",
    "            return\n",
    "        \n",
    "        input_text = self.entry.get()\n",
    "\n",
    "        #run the time-consuming function in a separate thread to keep the UI responsive\n",
    "        threading.Thread(target=self.process_input, args=(input_text,)).start()\n",
    "\n",
    "    def process_input(self, input_text):\n",
    "        self.present_output(input_text)  \n",
    "        self.display_image(\"new.png\") \n",
    "\n",
    "    def present_output(self, input_text):\n",
    "        doc = nlp(input_text) \n",
    "        input = get_parallel_tasks(doc)  \n",
    "        draw_petri_net(input)  \n",
    "        \n",
    "    def display_image(self, image_path):\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_image(0, 0, anchor=\"nw\", image=img_tk)\n",
    "            self.canvas.config(scrollregion=self.canvas.bbox(\"all\")) \n",
    "            self.canvas.image = img_tk  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x1622c1050>]\n",
      "{'I': ['do']}\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "app = PetriNetApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

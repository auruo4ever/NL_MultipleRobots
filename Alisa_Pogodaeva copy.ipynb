{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import snakes.plugins\n",
    "snakes.plugins.load(\"gv\", \"snakes.nets\", \"nets\")\n",
    "from nets import *\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_words = {\"and\", \"both\", \"along with\", \"as well as\", \"in conjunction with\", \"together with\"}\n",
    "individual_words = {\"or\", \"either\", \"one of\", \"neither\", \"nor\", \"any of\", \"each of\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [places, moves], Nouns: [table, (on), chair, None])\n"
     ]
    }
   ],
   "source": [
    "#Entities\n",
    "class Preposition:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.name})\"\n",
    "    \n",
    "    \n",
    "class Verb:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}\"\n",
    "\n",
    "class Noun:\n",
    "    def __init__(self, name, preposition=None):\n",
    "        self.name = name\n",
    "        self.preposition = preposition if isinstance(preposition, list) else [preposition]\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.preposition:\n",
    "            p = ', '.join(str(p) for p in self.preposition)\n",
    "            return f\"{self.name}, {p}\"\n",
    "        else:\n",
    "            return f\"{self.name}\"\n",
    "\n",
    "    \n",
    "class Task:\n",
    "    def __init__(self, verbs, nouns):\n",
    "        self.verbs = verbs if isinstance(verbs, list) else [verbs] \n",
    "        self.nouns = nouns if isinstance(nouns, list) else [nouns]\n",
    "    def __str__(self):\n",
    "        verb_str = ', '.join(str(verbs) for verbs in self.verbs)\n",
    "        nouns_str = ', '.join(str(noun) for noun in self.nouns)\n",
    "        return f\"Task(Verbs: [{verb_str}], Nouns: [{nouns_str}])\"\n",
    "    \n",
    "    def get_all_actors(self):\n",
    "        actors = []\n",
    "        for noun in self.nouns:\n",
    "            actors.extend(noun.name)  \n",
    "        return actors\n",
    "\n",
    "\n",
    "preposition1 = Preposition(\"on\")\n",
    "noun1 = Noun(\"table\", preposition1)\n",
    "noun2 = Noun(\"chair\")\n",
    "\n",
    "# Create a list of verbs\n",
    "verbs = Task([\"places\", \"moves\"], [noun1, noun2])\n",
    "\n",
    "# Print out the verb and its related nouns and prepositions\n",
    "print(verbs)  # Output: Verb(places, moves, Noun(table, floor, Preposition(on)), Noun(chair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_tree(doc):\n",
    "\n",
    "    all_tasks = []\n",
    "\n",
    "    def add_actors(subj):\n",
    "        prepositions = []\n",
    "        collect_prepositions(subj, prepositions)\n",
    "        actor = Noun(subj.text, prepositions)\n",
    "        return actor\n",
    "    \n",
    "    def add_task(verbs, actors):\n",
    "        task = Task(verbs, actors)\n",
    "        return task\n",
    "    \n",
    "    def add_verb(verb):\n",
    "        verb1 = Verb(verb.text)\n",
    "        return verb1\n",
    "\n",
    "    def collect_subj_conjuncts(subj, actors):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"conj\":\n",
    "                actor = add_actors(child)\n",
    "                actors.append(actor)\n",
    "                collect_subj_conjuncts(child, actors)\n",
    "    \n",
    "    def collect_prepositions(subj, prepositions):\n",
    "        for child in subj.children:\n",
    "            if child.dep_ == \"cc\":\n",
    "                preposition = Preposition(child.text)\n",
    "                prepositions.append(preposition)\n",
    "\n",
    "\n",
    "    def collect_conjuncts(verb, root_subject, verb_data):\n",
    "        for child in verb.children:\n",
    "            if child.dep_ == \"conj\" and child.pos_ == \"VERB\":\n",
    "                conj_nsubj = []\n",
    "\n",
    "                # Check if the conjunct verb has its own subject\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ == \"nsubj\":\n",
    "                        actor = add_actors(grandchild)\n",
    "                        conj_nsubj.append(actor)\n",
    "                        collect_subj_conjuncts(grandchild, conj_nsubj)\n",
    "\n",
    "                # If no subject for the conjunct verb, add it to the root's verb_data\n",
    "                if not conj_nsubj:\n",
    "                    verb = add_verb(child)\n",
    "                    verb_data.append(verb) \n",
    "                else:\n",
    "                    verb = add_verb(child)\n",
    "                    task = add_task(verb, conj_nsubj)\n",
    "                    all_tasks.append(task)\n",
    "\n",
    "                collect_conjuncts(child, root_subject, verb_data)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            verb = add_verb(token)\n",
    "            verb_data = [verb]  # Start with the root verb\n",
    "            actors_list = []\n",
    "\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"nsubj\":\n",
    "                    actor = add_actors(child)\n",
    "                    actors_list.append(actor)\n",
    "                    collect_subj_conjuncts(child, actors_list)\n",
    "\n",
    "            task = add_task(verb_data, actors_list)\n",
    "            all_tasks.append(task)\n",
    "            collect_conjuncts(token, actors_list, verb_data)\n",
    "\n",
    "    return all_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x1738ed990>]\n",
      "{'A': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'B': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'], 'C': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'],\n",
       " 'B': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0'],\n",
       " 'C': ['BARRIER_A_B_C_0', 'walk', 'SINC_A_B_C_0']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_or_exist(actors):\n",
    "    for actor in actors:\n",
    "        for p in actor.preposition:\n",
    "            if p.name == \"or\":\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_this_or(actor):\n",
    "    for p in actor.preposition:\n",
    "        if p.name == \"or\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_and_exist(actors):\n",
    "    for actor in actors:\n",
    "        for p in actor.preposition:\n",
    "            if p.name == \"and\":\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def print_actors_names(actors):\n",
    "    s = \"\"\n",
    "    for a in actors:\n",
    "        s+= a.name+(\"_\")\n",
    "    return s\n",
    "\n",
    "#rules for created dictionary\n",
    "def get_parallel_tasks(doc):\n",
    "    order_cnt = 0\n",
    "    actors_actions = {}\n",
    "    all_tasks = analyse_tree(doc)\n",
    "    print(all_tasks)\n",
    "\n",
    "    for task in all_tasks:\n",
    "        if len(task.nouns) > 1:\n",
    "            for verb in task.verbs:\n",
    "\n",
    "                #task choice\n",
    "                if (is_or_exist(task.nouns)): #gather actors groups if there is OR \n",
    "                    actors_before = []\n",
    "                    groups = \"\"\n",
    "                    for actor in task.nouns:\n",
    "                        if actor.name not in actors_actions:\n",
    "                            actors_actions[actor.name] = []\n",
    "                            actors_before.append(actor)\n",
    "                        if (is_this_or(actor)):\n",
    "                            if (is_and_exist(actors_before)):\n",
    "                                names_str = print_actors_names(actors_before)\n",
    "                                for a in actors_before:\n",
    "                                    actors_actions[a.name].append(\"OR_\" + names_str + str(order_cnt))\n",
    "                                    actors_actions[a.name].append(verb.name)\n",
    "                            else:\n",
    "                                for a in actors_before:\n",
    "                                    actors_actions[a.name].append(\"OR_\" + a.name + \"_\" + str(order_cnt))\n",
    "                                    actors_actions[a.name].append(verb.name) \n",
    "                            actors_before = []                           \n",
    "                    names_str = print_actors_names(actors_before)\n",
    "                    for a in actors_before:\n",
    "                        actors_actions[a.name].append(\"OR_\" + names_str + str(order_cnt))\n",
    "                        actors_actions[a.name].append(verb.name)\n",
    "                    print(groups)\n",
    "                    order_cnt+=1\n",
    "                    \n",
    "                #no choice\n",
    "                else:\n",
    "                    for actor in task.nouns:                                               \n",
    "                        if actor.name not in actors_actions:\n",
    "                            actors_actions[actor.name] = []\n",
    "                        names_str = print_actors_names(task.nouns)\n",
    "                        actors_actions[actor.name].append(\"BARRIER_\" + names_str + str(order_cnt))\n",
    "                        actors_actions[actor.name].append(verb.name)\n",
    "                        actors_actions[actor.name].append(\"SINC_\"+ names_str + str(order_cnt))\n",
    "                    order_cnt+=1\n",
    "        else:\n",
    "            actor = task.nouns[0]\n",
    "            if actor.name not in actors_actions:\n",
    "                    actors_actions[actor.name] = []\n",
    "            for verb in task.verbs:\n",
    "                    actors_actions[actor.name].append(verb.name)\n",
    "    print(actors_actions)\n",
    "    return actors_actions\n",
    "\n",
    "input_text =\"Robot A, Robot B and Robot C walk.\"\n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(['node_0', 'node_1'], [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = PetriNet('mynet')\n",
    "n.add_place(Place('p', [0]))\n",
    "n.add_transition(Transition('t', Expression('x<5')))\n",
    "n.add_input('p', 't', Variable('x'))\n",
    "n.add_output('p', 't', Expression('x+1'))\n",
    "n.draw(\"value-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Task object at 0x1738e5f50>]\n",
      "\n",
      "{'A': ['OR_A_B_0', 'walk'], 'B': ['OR_A_B_0', 'walk'], 'C': ['OR_C_0', 'walk']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': ['OR_A_B_0', 'walk'], 'B': ['OR_A_B_0', 'walk'], 'C': ['OR_C_0', 'walk']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "#OR cases\n",
    "\n",
    "#successful\n",
    "#input_text = \"Mary and Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark and John walk.\"\n",
    "#input_text = \"Mary, Ben or Mark walk.\"\n",
    "input_text = \"Robot A and Robot B, or Robot A and Robot C walk.\"\n",
    "\n",
    "\n",
    "doc = nlp(input_text)\n",
    "get_parallel_tasks(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task(Verbs: [goes], Nouns: [A])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/spacy/util.py:1835: UserWarning: [W124] 0.0.0.0:5000 is already in use, using the nearest available port 5001 as an alternative.\n",
      "  warnings.warn(Warnings.W124.format(host=host, port=start, serve_port=port))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bcfea333bde64997aa56a1fcc0a5fd8f-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Robot</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">A</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">goes.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bcfea333bde64997aa56a1fcc0a5fd8f-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bcfea333bde64997aa56a1fcc0a5fd8f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bcfea333bde64997aa56a1fcc0a5fd8f-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bcfea333bde64997aa56a1fcc0a5fd8f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,91.5 L237,79.5 253,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5001 ...\n",
      "\n",
      "Shutting down server on port 5001.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robots A and Robot C help each other\"\n",
    "#input_text = \"Robot A takes the pan, Robot B takes the pencil.\"\n",
    "#input_text = \"Robot A takes the pan and drops it. \"\n",
    "#input_text = \"Robot A, Robot B and Robot C takes the pan, Robot B takes the pencil\"\n",
    "#input_text = \"Robot A and Robot B take the pot. Robot C takes the spoon. Robot A and Robot C work together and Robot B is cleaning\"\n",
    "\n",
    "#WEIRD BEHAVIOUR in spacy\n",
    "#input_text = \"Robots A and Robot C help each other and Robot B is cleaning\"\n",
    "#input_text = \"Robots A and Robot C help each other, Robot B cleans\"\n",
    "\n",
    "input_text = \"Robot A goes.\"\n",
    "\n",
    "doc = nlp(input_text)\n",
    "all_tasks = analyse_tree(doc)\n",
    "for i in all_tasks:\n",
    "    print(i)\n",
    "\n",
    "#options={\"compact\": True, \"distance\":60}\n",
    "spacy.displacy.serve(doc, style=\"dep\", auto_select_port=True)\n",
    "#print_tasks(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_input():\n",
    "    input_text = entry.get()\n",
    "    label.config(text=input_text)\n",
    "    \n",
    "    doc = nlp(input_text)\n",
    "    result_text.delete(1.0, tk.END)\n",
    "    \n",
    "   \n",
    "    subjects_info = analyse_tree(doc)\n",
    "    # Insert the subjects and conjuncts information into the text area\n",
    "    result_text.insert(tk.END, subjects_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "label = tk.Label(root, text=\"Your input will appear here\", font=('Arial', 14))\n",
    "label.pack(pady=10)\n",
    "entry = tk.Entry(root, font=('Arial', 14))\n",
    "entry.pack(pady=10)\n",
    "button = tk.Button(root, text=\"Analyze\", command=display_input, font=('Arial', 14))\n",
    "button.pack(pady=10)\n",
    "result_text = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=15, font=('Arial', 12))\n",
    "result_text.pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Foundations of infovis ðŸš€\n",
    "\n",
    "Let's get started with exploring some datasets with basic chart types!\n",
    "\n",
    "ðŸ‘‰ This part has two TODOs (1.1, 1.2)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, here are the references for the data we use for some examples: \n",
    "\n",
    "- \"Global air quality data provided by the World Health Organization\" | [Source: WHO](https://www.who.int/data/gho/data/themes/air-pollution/who-air-quality-database)\n",
    "\n",
    "- \"WHO regional groupings\" by income | [Source: WHO](https://cdn.who.int/media/docs/default-source/air-pollution-documents/air-quality-and-health/country-groupings-database-2022.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and have a first look:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
